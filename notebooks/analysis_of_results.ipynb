{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function, unicode_literals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Results(object):\n",
    "    def __init__(self, name, exp_name, base_dir, iteration_slice, rtype='test'):\n",
    "        self.name = name\n",
    "        self.size = len(iteration_slice)\n",
    "\n",
    "        for idx, it in enumerate(iteration_slice):\n",
    "            dirname = os.path.join(base_dir, \"iter{}\".format(it), exp_name)\n",
    "            \n",
    "            for result_kind in ['accuracy', 'precision', 'recall', 'predictions']:\n",
    "                for rfile in filter(lambda x: x.startswith(\"{}_{}\".format(rtype, result_kind)), os.listdir(dirname)):\n",
    "                    if \"NEU\" in rfile:\n",
    "                        ekind = \"NEU\"\n",
    "                    elif \"LKIF\" in rfile:\n",
    "                        ekind = \"LKIF\"\n",
    "                    elif \"NEP\" in rfile:\n",
    "                        ekind = \"NEP\"\n",
    "                    else:\n",
    "                        ekind = \"NER\"\n",
    "                    \n",
    "                    attr_name = \"{}_{}\".format(result_kind, ekind)\n",
    "                    filepath = os.path.join(dirname, rfile)\n",
    "                    \n",
    "                    if idx == 0:\n",
    "                        setattr(self, attr_name, [])\n",
    "                    \n",
    "                    if result_kind != 'predictions':\n",
    "                        getattr(self, attr_name).append(np.loadtxt(filepath, delimiter=','))\n",
    "                    else:\n",
    "                        df = pd.read_csv(filepath, header=None,\n",
    "                                         names=[\"prediction\", \"prediction_label\", \"true\", \"true_label\"])\n",
    "                        \n",
    "                        if idx == 0:\n",
    "                            setattr(self, \"classes_{}\".format(ekind), np.unique(df.true_label.values))\n",
    "                            setattr(self, \"true_{}\".format(ekind), df.true.values)\n",
    "                        \n",
    "                        getattr(self, attr_name).append(df.prediction.values)\n",
    "\n",
    "        for attr, value in self.__dict__.iteritems():\n",
    "            if isinstance(value, list):\n",
    "                setattr(self, attr, np.array(value))\n",
    "\n",
    "rng = range(1, 6)\n",
    "\n",
    "NEU = Results(\"MLP without CL\", \"NEU_10500\", \"../../results/final_results/\", rng)\n",
    "LKIF = Results(\"MLP without CL\", \"LKIF_10500\", \"../../results/final_results/\", rng)\n",
    "CL1 = Results(\"CL change layer\", \"CL_10500\", \"../../results/final_results/\", rng)\n",
    "CL2 = Results(\"CL remove layer\", \"CL_10500_10172_7_3\", \"../../results/final_results/\", rng)\n",
    "\n",
    "NEU_pairs = [(NEU, CL1), (NEU, CL2), (CL1, CL2)]\n",
    "LKIF_pairs = [(LKIF, CL1), (LKIF, CL2), (CL1, CL2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_names = np.array([\"Experiment 1\", \"Experiment 2\", \"Iteration\", \"Statistic\", \"P-value\", \"Significative\"])\n",
    "NEU_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "for p1, p2 in NEU_pairs:\n",
    "    for i in range(p1.size):\n",
    "        tstat, pvalue = ttest_rel(p1.predictions_NEU[i], p2.predictions_NEU[i])\n",
    "        values = [p1.name, p2.name, i+1, tstat, pvalue, \"Yes\" if pvalue < 0.05 else \"No\"]\n",
    "        NEU_df = NEU_df.append(dict(zip(col_names, values)), ignore_index=True)\n",
    "\n",
    "print(NEU_df.to_latex(float_format='{:.2g}'.format, index=False, columns=col_names[col_names != \"Statistic\"]))\n",
    "with open(\"../../paper/NEU_significance.tex\", \"w\") as f:\n",
    "    print(NEU_df.to_latex(float_format='{:.2g}'.format, index=False, columns=col_names[col_names != \"Statistic\"]),\n",
    "          file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = np.array([\"Experiment 1\", \"Experiment 2\", \"Iteration\", \"Statistic\", \"P-value\", \"Significative\"])\n",
    "LKIF_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "for p1, p2 in LKIF_pairs:\n",
    "    for i in range(p1.size):\n",
    "        tstat, pvalue = ttest_rel(p1.predictions_LKIF[i], p2.predictions_LKIF[i])\n",
    "        values = [p1.name, p2.name, i+1, tstat, pvalue, \"Yes\" if pvalue < 0.05 else \"No\"]\n",
    "        LKIF_df = LKIF_df.append(dict(zip(col_names, values)), ignore_index=True)\n",
    "\n",
    "print(LKIF_df.to_latex(float_format='{:.2g}'.format, index=False, columns=col_names[col_names != \"Statistic\"]))\n",
    "with open(\"../../paper/LKIF_significance.tex\", \"w\") as f:\n",
    "    print(LKIF_df.to_latex(float_format='{:.2g}'.format, index=False, columns=col_names[col_names != \"Statistic\"]),\n",
    "          file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEU_rslt_df = pd.DataFrame(columns=\"name accuracy precision recall fscore\".split())\n",
    "\n",
    "for rslt in [NEU, CL1, CL2]:\n",
    "    pmean = rslt.precision_NEU[:, rslt.classes_NEU != 'O'].mean()\n",
    "    rmean = rslt.recall_NEU[:, rslt.classes_NEU != 'O'].mean()\n",
    "    NEU_rslt_df = NEU_rslt_df.append({\n",
    "            \"name\": rslt.name,\n",
    "            \"accuracy\": rslt.accuracy_NEU.mean(),\n",
    "            \"precision\": pmean,\n",
    "            \"recall\": rmean,\n",
    "            \"fscore\": 2 * pmean * rmean / (pmean + rmean)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "display(HTML(NEU_rslt_df.to_html(float_format='{:.3f}'.format, index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LKIF_rslt_df = pd.DataFrame(columns=\"name accuracy precision recall fscore\".split())\n",
    "LKIF_rslt_pr = []\n",
    "\n",
    "for rslt in [LKIF, CL1, CL2]:\n",
    "    pmean = rslt.precision_LKIF[:, rslt.classes_LKIF != 'O'].mean()\n",
    "    rmean = rslt.recall_LKIF[:, rslt.classes_LKIF != 'O'].mean()\n",
    "    LKIF_rslt_df = LKIF_rslt_df.append({\n",
    "        \"name\": rslt.name,\n",
    "        \"accuracy\": rslt.accuracy_LKIF.mean(),\n",
    "        \"precision\": pmean,\n",
    "        \"recall\": rmean,\n",
    "        \"fscore\": 2 * pmean * rmean / (pmean + rmean)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    LKIF_rslt_pr.append([rslt.name + \" precision\"] +\\\n",
    "                        list(rslt.precision_LKIF[:, rslt.classes_LKIF != 'O'].mean(axis=0)))\n",
    "    LKIF_rslt_pr.append([rslt.name + \" recall\"] + list(rslt.recall_LKIF[:, rslt.classes_LKIF != 'O'].mean(axis=0)))\n",
    "\n",
    "LKIF_rslt_pr = pd.DataFrame(LKIF_rslt_pr, columns=[\"Name\"] + list(LKIF.classes_LKIF[LKIF.classes_LKIF != 'O']))\n",
    "    \n",
    "display(HTML(LKIF_rslt_df.to_html(float_format='{:.3f}'.format, index=False)))\n",
    "print\n",
    "display(HTML(LKIF_rslt_pr.to_html(float_format='{:.3f}'.format, index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "_, counts = np.unique(NEU.true_NEU, return_counts=True)\n",
    "hist = np.histogram(counts, bins=[0, 10, 25, 100, counts.shape[0]])[0]\n",
    "bins = [\"0 <= x < 10\", \"10 <= x < 25\", \"25 <= x < 100\", \"100 <= x\"]\n",
    "ax = sns.barplot(bins, hist)\n",
    "ax.set(xlabel='Occurrence bins', ylabel='Number of classes', title='Number of Classes per Occurrence Bins')\n",
    "ax.title.set_y(1.05)\n",
    "ax.xaxis.labelpad = 10\n",
    "ax.yaxis.labelpad = 15\n",
    "\n",
    "# plt.savefig(\"../../paper/graphics/occurrences.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "_, counts = np.unique(LKIF.true_LKIF, return_counts=True)\n",
    "hist = np.histogram(counts, bins= [0, 1e3, 3e4, 1e5, 2e5])[0]\n",
    "bins = [\"Less\", \"Rare\", \"Medium\", \"Most\"]\n",
    "ax = sns.barplot(bins, hist)\n",
    "ax.set(xlabel='Occurrence bins', ylabel='Number of classes', title='Number of Classes per Occurrence Bins')\n",
    "ax.title.set_y(1.05)\n",
    "ax.xaxis.labelpad = 10\n",
    "ax.yaxis.labelpad = 15\n",
    "\n",
    "# plt.savefig(\"../../paper/graphics/occurrences_LKIF.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.25)\n",
    "\n",
    "top_classes = 100\n",
    "\n",
    "_, counts = np.unique(NEU.true_NEU, return_counts=True)\n",
    "\n",
    "most_populated = np.argsort(counts)[::-1][:top_classes]\n",
    "count_threshold = counts[most_populated][-1]\n",
    "\n",
    "def mapping(label):\n",
    "    if counts[label] < 10:\n",
    "        return \"Less\"\n",
    "    elif counts[label] < 25:\n",
    "        return \"Rare\"\n",
    "    elif counts[label] < count_threshold:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return NEU.classes_NEU[label]\n",
    "vmapping = np.vectorize(mapping)\n",
    "bins = [\"Less\", \"Rare\", \"Medium\"] + list(NEU.classes_NEU[most_populated][::-1])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharey=True, figsize=(15, 7))\n",
    "\n",
    "for idx, rlt in enumerate([NEU, CL1, CL2]):\n",
    "    true_NEU_mapped = vmapping(rlt.true_NEU)\n",
    "    pred_NEU_mapped = vmapping(rlt.predictions_NEU[0])\n",
    "\n",
    "    cm = confusion_matrix(true_NEU_mapped, pred_NEU_mapped)\n",
    "    normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    normalized_cm = pd.DataFrame(normalized_cm, columns=bins, index=bins)\n",
    "\n",
    "    ax = sns.heatmap(normalized_cm.reindex(index=normalized_cm.index[::-1]), vmin=0.0, vmax=1.0, annot=False,\n",
    "                     fmt=\".2f\", linewidths=.5, cmap=\"Blues\", ax=axes[idx], cbar=False)\n",
    "    ax.set_title(rlt.name)\n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_rotation(30)\n",
    "    \n",
    "    ax.title.set_y(1.05)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Normalized confusion matrices for entity linking experiments divided by occurrence bins\", fontsize=20)\n",
    "fig.tight_layout(pad=2.5)\n",
    "\n",
    "plt.savefig(\"../../paper/graphics/heatmaps_{}_classes.png\".format(top_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for t in os.listdir(\"../../results/final_results/lkif/\"):\n",
    "    with open(\"../../results/final_results/lkif/\" + t, \"r\") as f:\n",
    "        dataset.extend([l.strip().split(\"\\t\") for l in f.read().decode(\"utf-8\").split(\"\\n\") if l.strip() != ''])\n",
    "\n",
    "dataset = pd.DataFrame(dataset, columns=\"Instance true_LKIF predictions_LKIF\".split())\n",
    "STF = Results(\"Stanford NER\", \"STF\", \"../../results/final_results/\", range(0))\n",
    "classes, inverse = np.unique(dataset.true_LKIF.values, return_inverse=True)\n",
    "setattr(STF, 'true_LKIF', inverse)\n",
    "setattr(STF, 'classes_LKIF', classes)\n",
    "classes, inverse = np.unique(dataset.predictions_LKIF.values, return_inverse=True)\n",
    "setattr(STF, 'predictions_LKIF', [inverse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.25)\n",
    "\n",
    "_, counts = np.unique(LKIF.true_LKIF, return_counts=True)\n",
    "_, counts_stf = np.unique(STF.true_LKIF, return_counts=True)\n",
    "\n",
    "def mapping(label):\n",
    "    if counts[label] < 1e3:\n",
    "        return \"Less\"\n",
    "    elif counts[label] < 5e4:\n",
    "        return \"Rare\"\n",
    "    elif counts[label] < 1e5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Most\"\n",
    "\n",
    "def stf_mapping(label):\n",
    "    if counts_stf[label] < 1e3:\n",
    "        return \"Less\"\n",
    "    elif counts_stf[label] < 1e5:\n",
    "        return \"Rare\"\n",
    "    elif counts_stf[label] < 2e5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Most\"\n",
    "\n",
    "vmapping = np.vectorize(mapping)\n",
    "vmapping_stf = np.vectorize(stf_mapping)\n",
    "bins = [\"Less populated\", \"Rare populated\", \"Medium populated\", \"Most populated\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 6))\n",
    "\n",
    "for idx, rlt in enumerate([LKIF, CL1, CL2, STF]):\n",
    "    if rlt.name != \"Stanford NER\":\n",
    "        true_LKIF_mapped = vmapping(rlt.true_LKIF)\n",
    "        pred_LKIF_mapped = vmapping(rlt.predictions_LKIF[0])\n",
    "    else:\n",
    "        true_LKIF_mapped = vmapping_stf(rlt.true_LKIF)\n",
    "        pred_LKIF_mapped = vmapping_stf(rlt.predictions_LKIF[0])\n",
    "\n",
    "    cm = confusion_matrix(true_LKIF_mapped, pred_LKIF_mapped)\n",
    "    normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    normalized_cm = pd.DataFrame(normalized_cm, columns=bins, index=bins)\n",
    "\n",
    "    ax = sns.heatmap(normalized_cm.reindex(index=normalized_cm.index[::-1]), vmin=0.0, vmax=1.0, annot=True,\n",
    "                     fmt=\".2f\", linewidths=.5, cmap=\"Blues\", ax=axes.flatten()[idx], cbar=False)\n",
    "    ax.set_title(rlt.name)\n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_rotation(30)\n",
    "\n",
    "fig.suptitle(\"Normalized confusion matrices for entity linking experiments \" +\n",
    "             \"divided by occurrence bins for LKIF classes\", fontsize=20)\n",
    "fig.tight_layout(pad=2.5)\n",
    "\n",
    "plt.savefig(\"../../paper/graphics/heatmaps_LKIF.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
